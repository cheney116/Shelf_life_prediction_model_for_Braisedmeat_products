{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0e995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, accuracy_score,f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4198f2c-a4b6-46f4-ab23-2b8022649730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the encoded data\n",
    "encoded_data_dir = 'encoded_data'\n",
    "\n",
    "# Load the list of encoded data files\n",
    "files = os.listdir(encoded_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c595b09d-67e1-4367-9bed-7798f608112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define dictionaries to store the ROC AUC and F1 scores for each encoding method\n",
    "roc_auc_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "for encoding_file in files:\n",
    "    \n",
    "    # Load the encoded data\n",
    "    encoded_data = pd.read_csv(os.path.join(encoded_data_dir, encoding_file))\n",
    "    \n",
    "    # Split the encoded data into features and labels\n",
    "    X = encoded_data.drop(columns=['target'])\n",
    "    y = encoded_data['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovo')\n",
    "    f1 = f1_score(y_test, model.predict(X_test), average='macro')\n",
    "    \n",
    "    # Store the scores for this encoding method\n",
    "    roc_auc_scores[encoding_file] = roc_auc\n",
    "    f1_scores[encoding_file] = f1\n",
    "    \n",
    "# Output the scores for each encoding method to a separate file\n",
    "with open('scores_RandomForest.txt', 'w') as f:\n",
    "    for encoding_file in files:\n",
    "        f.write(f'Encoding method: {encoding_file}\\n')\n",
    "        f.write(f'ROC AUC score: {roc_auc_scores[encoding_file]:.2f}\\n')\n",
    "        f.write(f'F1 score: {f1_scores[encoding_file]:.2f}\\n\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5917af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got [    0    99   999  9999 99999]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     28\u001b[0m test_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1471\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1468\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1470\u001b[0m ):\n\u001b[1;32m-> 1471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1472\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1473\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1474\u001b[0m     )\n\u001b[0;32m   1476\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got [    0    99   999  9999 99999]"
     ]
    }
   ],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define dictionaries to store the ROC AUC and F1 scores for each encoding method\n",
    "roc_auc_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# Train and evaluate an XGBClassifier model with each encoding method\n",
    "for encoding_file in files:\n",
    "    \n",
    "    # Load the encoded data\n",
    "    encoded_data = pd.read_csv(os.path.join(encoded_data_dir, encoding_file))\n",
    "    \n",
    "    # Split the encoded data into features and labels\n",
    "    X = encoded_data.drop(columns=['target'])\n",
    "    y = encoded_data['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Adjust target variable if minimum value is 1\n",
    "    if y_train.min() == 1:\n",
    "        y_train -= 1\n",
    "        y_test -= 1\n",
    "    \n",
    "    # Train the model\n",
    "    model = XGBClassifier(random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_preds = model.predict_proba(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, test_preds, multi_class='ovo')\n",
    "    f1 = f1_score(y_test, model.predict(X_test), average='macro')\n",
    "    \n",
    "    # Store the scores for this encoding method\n",
    "    roc_auc_scores[encoding_file] = roc_auc\n",
    "    f1_scores[encoding_file] = f1\n",
    "    \n",
    "# Output the scores for each encoding method to a separate file\n",
    "with open('scores_XGBoost.txt', 'w') as f:\n",
    "    for encoding_file in files:\n",
    "        f.write(f'Encoding method: {encoding_file}\\n')\n",
    "        f.write(f'ROC AUC score: {roc_auc_scores[encoding_file]:.2f}\\n')\n",
    "        f.write(f'F1 score: {f1_scores[encoding_file]:.2f}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f9332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and evaluate a SVM model\n",
    "\n",
    "# Define dictionaries to store the ROC AUC and F1 scores for each encoding method\n",
    "roc_auc_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# Train and evaluate a support vector machine with each encoding method\n",
    "for encoding_file in files:\n",
    "    \n",
    "    # Load the encoded data\n",
    "    encoded_data = pd.read_csv(os.path.join(encoded_data_dir, encoding_file))\n",
    "    \n",
    "    # Split the encoded data into features and labels\n",
    "    X = encoded_data.drop(columns=['target'])\n",
    "    y = encoded_data['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model = SVC(probability=True, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_preds = model.predict_proba(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, test_preds, multi_class='ovo')\n",
    "    f1 = f1_score(y_test, model.predict(X_test), average='macro')\n",
    "    \n",
    "    # Store the scores for this encoding method\n",
    "    roc_auc_scores[encoding_file] = roc_auc\n",
    "    f1_scores[encoding_file] = f1\n",
    "    \n",
    "# Output the scores for each encoding method to a separate file\n",
    "with open('scores_SVM.txt', 'w') as f:\n",
    "    for encoding_file in files:\n",
    "        f.write(f'Encoding method: {encoding_file}\\n')\n",
    "        f.write(f'ROC AUC score: {roc_auc_scores[encoding_file]:.2f}\\n')\n",
    "        f.write(f'F1 score: {f1_scores[encoding_file]:.2f}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724374fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and evaluate a KNeighborsClassifier  model\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define dictionaries to store the ROC AUC and F1 scores for each encoding method\n",
    "roc_auc_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# Train and evaluate a KNN model with each encoding method\n",
    "for encoding_file in files:\n",
    "    \n",
    "    # Load the encoded data\n",
    "    encoded_data = pd.read_csv(os.path.join(encoded_data_dir, encoding_file))\n",
    "    \n",
    "    # Split the encoded data into features and labels\n",
    "    X = encoded_data.drop(columns=['target'])\n",
    "    y = encoded_data['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_preds = model.predict_proba(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, test_preds, multi_class='ovo')\n",
    "    f1 = f1_score(y_test, model.predict(X_test), average='macro')\n",
    "    \n",
    "    # Store the scores for this encoding method\n",
    "    roc_auc_scores[encoding_file] = roc_auc\n",
    "    f1_scores[encoding_file] = f1\n",
    "    \n",
    "# Output the scores for each encoding method to a separate file\n",
    "with open('scores_KNN.txt', 'w') as f:\n",
    "    for encoding_file in files:\n",
    "        f.write(f'Encoding method: {encoding_file}\\n')\n",
    "        f.write(f'ROC AUC score: {roc_auc_scores[encoding_file]:.2f}\\n')\n",
    "        f.write(f'F1 score: {f1_scores[encoding_file]:.2f}\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3319f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Define dictionaries to store the ROC AUC and F1 scores for each encoding method\n",
    "roc_auc_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# Assuming 'files' is a list of filenames and 'encoded_data_dir' is defined\n",
    "for encoding_file in files:\n",
    "    \n",
    "   \n",
    "    # Load the encoded data\n",
    "    encoded_data = pd.read_csv(os.path.join(encoded_data_dir, encoding_file))\n",
    "    \n",
    "    # Split the encoded data into features and labels, removing the target from features\n",
    "    features = encoded_data.drop(columns=['target'])\n",
    "    labels = encoded_data['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model = MLPClassifier(hidden_layer_sizes=(3,), max_iter=10000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_probs = model.predict_proba(X_test)\n",
    "    if len(set(labels)) == 2:  # Binary classification\n",
    "        roc_auc = roc_auc_score(y_test, test_probs[:, 1])\n",
    "    else:  # Multi-class classification\n",
    "        roc_auc = roc_auc_score(y_test, test_probs, multi_class='ovo')\n",
    "    f1 = f1_score(y_test, model.predict(X_test), average='macro')\n",
    "    \n",
    "    # Store the scores for this encoding method\n",
    "    roc_auc_scores[encoding_file] = roc_auc\n",
    "    f1_scores[encoding_file] = f1\n",
    "    \n",
    "# Output the scores for each encoding method to a separate file\n",
    "with open('scores_MLP.txt', 'w') as f:\n",
    "    for encoding_file in files:\n",
    "        f.write(f'Encoding method: {encoding_file}\\n')\n",
    "        f.write(f'ROC AUC score: {roc_auc_scores[encoding_file]:.2f}\\n')\n",
    "        f.write(f'F1 score: {f1_scores[encoding_file]:.2f}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and evaluate a GaussianNB  model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define dictionaries to store the ROC AUC and F1 scores for each encoding method\n",
    "roc_auc_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# Train and evaluate a Naive Bayes model with each encoding method\n",
    "for encoding_file in files:\n",
    "    \n",
    "    # Load the encoded data\n",
    "    encoded_data = pd.read_csv(os.path.join(encoded_data_dir, encoding_file))\n",
    "    \n",
    "    # Split the encoded data into features and labels\n",
    "    X = encoded_data.drop(columns=['target'])\n",
    "    y = encoded_data['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_preds = model.predict_proba(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, test_preds, multi_class='ovo')\n",
    "    f1 = f1_score(y_test, model.predict(X_test), average='macro')\n",
    "    \n",
    "    # Store the scores for this encoding method\n",
    "    roc_auc_scores[encoding_file] = roc_auc\n",
    "    f1_scores[encoding_file] = f1\n",
    "    \n",
    "# Output the scores for each encoding method to a separate file\n",
    "with open('scores_GaussianNB.txt', 'w') as f:\n",
    "    for encoding_file in files:\n",
    "        f.write(f'Encoding method: {encoding_file}\\n')\n",
    "        f.write(f'ROC AUC score: {roc_auc_scores[encoding_file]:.2f}\\n')\n",
    "        f.write(f'F1 score: {f1_scores[encoding_file]:.2f}\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a0947",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and evaluate a LogisticRegression model\n",
    "\n",
    "\n",
    "# Define dictionaries to store the ROC AUC and F1 scores for each encoding method\n",
    "roc_auc_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# Train and evaluate a logistic regression model with each encoding method\n",
    "for encoding_file in files:\n",
    "    \n",
    "    # Load the encoded data\n",
    "    encoded_data = pd.read_csv(os.path.join(encoded_data_dir, encoding_file))\n",
    "    \n",
    "    # Split the encoded data into features and labels\n",
    "    train_encoded_data, test_encoded_data, train_labels, test_labels = train_test_split(encoded_data.drop(columns=['target']), encoded_data['target'], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model = LogisticRegression(max_iter=10000, solver='lbfgs')\n",
    "    model.fit(train_encoded_data, train_labels)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_preds = model.predict_proba(test_encoded_data)\n",
    "    roc_auc = roc_auc_score(test_labels, test_preds, multi_class='ovo')\n",
    "    f1 = f1_score(test_labels, model.predict(test_encoded_data), average='macro')\n",
    "    \n",
    "    # Store the scores for this encoding method\n",
    "    roc_auc_scores[encoding_file] = roc_auc\n",
    "    f1_scores[encoding_file] = f1\n",
    "    \n",
    "# Output the scores for each encoding method to a separate file\n",
    "\n",
    "\n",
    "with open('scores_LogisticRegression.txt', 'w') as f:\n",
    "    \n",
    "    for encoding_file in files:   \n",
    "        f.write(f'Encoding method: {encoding_file}\\n')\n",
    "        f.write(f'ROC AUC score: {roc_auc_scores[encoding_file]:.2f}\\n')\n",
    "        f.write(f'F1 score: {f1_scores[encoding_file]:.2f}\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Define dictionaries to store the ROC AUC and F1 scores for each encoding method\n",
    "roc_auc_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# Train and evaluate a Decision Tree model with each encoding method\n",
    "for encoding_file in files:\n",
    "    \n",
    "    # Load the encoded data\n",
    "    encoded_data = pd.read_csv(os.path.join(encoded_data_dir, encoding_file))\n",
    "    \n",
    "    # Split the encoded data into features and labels\n",
    "    train_encoded_data, test_encoded_data, train_labels, test_labels = train_test_split(encoded_data.drop(columns=['target']), encoded_data['target'], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(train_encoded_data, train_labels)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_preds = model.predict_proba(test_encoded_data)\n",
    "    roc_auc = roc_auc_score(test_labels, test_preds, multi_class='ovo')\n",
    "    f1 = f1_score(test_labels, model.predict(test_encoded_data), average='macro')\n",
    "    \n",
    "    # Store the scores for this encoding method\n",
    "    roc_auc_scores[encoding_file] = roc_auc\n",
    "    f1_scores[encoding_file] = f1\n",
    "    \n",
    "    # Output the scores for this encoding method to a separate file\n",
    "with open('scores_DecisionTree.txt', 'w') as f:\n",
    "    \n",
    "    for encoding_file in files:   \n",
    "        f.write(f'Encoding method: {encoding_file}\\n')\n",
    "        f.write(f'ROC AUC score: {roc_auc_scores[encoding_file]:.2f}\\n')\n",
    "        f.write(f'F1 score: {f1_scores[encoding_file]:.2f}\\n\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2967d-392f-42ae-9dc3-e2dd5a168e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train and evaluate a Gradient Boosting model with each encoding method\n",
    "for encoding_file in files:\n",
    "    \n",
    "    # Load the encoded data\n",
    "    encoded_data = pd.read_csv(os.path.join(encoded_data_dir, encoding_file))\n",
    "    \n",
    "    # Split the encoded data into features and labels\n",
    "    train_encoded_data, test_encoded_data, train_labels, test_labels = train_test_split(encoded_data.drop(columns=['target']), encoded_data['target'], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model = GradientBoostingClassifier(random_state=42)\n",
    "    model.fit(train_encoded_data, train_labels)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_preds = model.predict_proba(test_encoded_data)\n",
    "    roc_auc = roc_auc_score(test_labels, test_preds, multi_class='ovo')\n",
    "    f1 = f1_score(test_labels, model.predict(test_encoded_data), average='macro')\n",
    "    \n",
    "    # Store the scores for this encoding method\n",
    "    roc_auc_scores[encoding_file] = roc_auc\n",
    "    f1_scores[encoding_file] = f1\n",
    "    \n",
    "    # Output the scores for this encoding method to a separate file\n",
    "with open('scores_GradientBoosting.txt', 'w') as f:\n",
    "    \n",
    "    for encoding_file in files:   \n",
    "        f.write(f'Encoding method: {encoding_file}\\n')\n",
    "        f.write(f'ROC AUC score: {roc_auc_scores[encoding_file]:.2f}\\n')\n",
    "        f.write(f'F1 score: {f1_scores[encoding_file]:.2f}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc06fb-43a7-4c55-9b56-2142d2eca5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define dictionaries to store the ROC AUC and F1 scores for each encoding method\n",
    "roc_auc_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# Train and evaluate a neural network model with each encoding method\n",
    "for encoding_file in files:\n",
    "    \n",
    "    # Load the encoded data\n",
    "    encoded_data = pd.read_csv(os.path.join(encoded_data_dir, encoding_file))\n",
    "    \n",
    "    # Split the encoded data into features and labels\n",
    "    X = encoded_data.drop(columns=['target']).values\n",
    "    y = encoded_data['target'].values\n",
    "    \n",
    "    # Standardize the input features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if y_train.min() == 1:\n",
    "        y_train -= 1\n",
    "        y_test -= 1\n",
    "    \n",
    "    # Define the neural network model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))  # Assuming 8 classes for the target variable\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_preds = model.predict(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, test_preds, multi_class='ovo')\n",
    "    f1 = f1_score(y_test, np.argmax(test_preds, axis=1), average='macro')\n",
    "    \n",
    "    # Store the scores for this encoding method\n",
    "    roc_auc_scores[encoding_file] = roc_auc\n",
    "    f1_scores[encoding_file] = f1\n",
    "    \n",
    "    # Output the scores for this encoding method to a separate file\n",
    "with open('scores_NeuralNetwork.txt', 'w') as f:\n",
    "    \n",
    "    for encoding_file in files: \n",
    "        f.write(f'Encoding method: {encoding_file}\\n')\n",
    "        f.write(f'ROC AUC score: {roc_auc_scores[encoding_file]:.2f}\\n')\n",
    "        f.write(f'F1 score: {f1_scores[encoding_file]:.2f}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Train and evaluate an AdaBoost model with each encoding method\n",
    "roc_auc_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "for encoding_file in files:\n",
    "    \n",
    "    # Load the encoded data\n",
    "    encoded_data = pd.read_csv(os.path.join(encoded_data_dir, encoding_file))\n",
    "    \n",
    "    # Split the encoded data into features and labels\n",
    "    train_encoded_data, test_encoded_data, train_labels, test_labels = train_test_split(\n",
    "        encoded_data.drop(columns=['target']), encoded_data['target'], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model using AdaBoost with the SAMME algorithm\n",
    "    model = AdaBoostClassifier(algorithm=\"SAMME\", random_state=42)\n",
    "    model.fit(train_encoded_data, train_labels)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_preds = model.predict_proba(test_encoded_data)\n",
    "    roc_auc = roc_auc_score(test_labels, test_preds, multi_class='ovo')\n",
    "    f1 = f1_score(test_labels, model.predict(test_encoded_data), average='macro')\n",
    "    \n",
    "    # Store the scores for this encoding method\n",
    "    roc_auc_scores[encoding_file] = roc_auc\n",
    "    f1_scores[encoding_file] = f1\n",
    "    \n",
    "# Output the scores for this encoding method to a separate file\n",
    "with open('scores_AdaBoost_SAMME.txt', 'w') as f:\n",
    "    for encoding_file in files:   \n",
    "        f.write(f'Encoding method: {encoding_file}\\n')\n",
    "        f.write(f'ROC AUC score: {roc_auc_scores[encoding_file]:.2f}\\n')\n",
    "        f.write(f'F1 score: {f1_scores[encoding_file]:.2f}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55542a30-066f-4a27-a374-a0bb6f25d6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
