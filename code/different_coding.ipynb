{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfac6c37-7b61-4850-810e-487e793a591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
    "from category_encoders import BinaryEncoder, BaseNEncoder, CountEncoder, TargetEncoder, CatBoostEncoder, \\\n",
    "                             JamesSteinEncoder, MEstimateEncoder, LeaveOneOutEncoder, PolynomialEncoder, \\\n",
    "                             HelmertEncoder, BackwardDifferenceEncoder, HashingEncoder, SumEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "from scipy import sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4b88e5c-32fe-421f-af1f-c4a35ebcff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data22.csv')\n",
    "\n",
    "\n",
    "# Create a folder to store encoded files\n",
    "if not os.path.exists('encoded_data'):\n",
    "    os.makedirs('encoded_data')\n",
    "\n",
    "\n",
    "# Explicitly convert columns to categorical if they are not already\n",
    "categorical_columns = ['package', 'preservative', 'sterilization', 'temperature']  # Add 'temperature' if it's categorical too\n",
    "for col in categorical_columns:\n",
    "    data[col] = data[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40fe77e7-d331-4c08-b0f1-9ab29ec4edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method 1: Label Encoding\n",
    "le = LabelEncoder()\n",
    "le_data = data.apply(le.fit_transform)\n",
    "le_data.to_csv('encoded_data/label_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fafc46eb-ad3a-4e0a-92af-f63b431ada7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method 2: Ordinal Encoding\n",
    "oe = OrdinalEncoder()\n",
    "oe_data = oe.fit_transform(data)\n",
    "oe_data = pd.DataFrame(oe_data, columns=data.columns)\n",
    "oe_data.to_csv('encoded_data/ordinal_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3445fadc-5ce7-47aa-87ce-7cd75f602a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method 3: One-hot encoding\n",
    "ohe = OneHotEncoder()\n",
    "ohe_data = ohe.fit_transform(data)\n",
    "# Update the method call below\n",
    "ohe_data = pd.DataFrame(ohe_data.toarray(), columns=ohe.get_feature_names_out(data.columns))\n",
    "\n",
    "# Drop the individual target columns\n",
    "ohe_data.drop(columns=ohe_data.filter(like='target').columns, inplace=True)\n",
    "\n",
    "# Add the 'target' column from the original data\n",
    "ohe_data['target'] = data['target']\n",
    "\n",
    "\n",
    "ohe_data.to_csv('encoded_data/onehot_encoded.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6738bba8-3062-4046-88d9-62bd5b91f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method 4: Binary Encoding\n",
    "be = BinaryEncoder()\n",
    "be_data = be.fit_transform(data)\n",
    "be_data.to_csv('encoded_data/binary_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eb7ef2f-52f9-4882-89cc-605cd9fcaec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method 5: Base-N Encoding\n",
    "bne = BaseNEncoder(base=3)\n",
    "bne_data = bne.fit_transform(data)\n",
    "bne_data.to_csv('encoded_data/basen_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f1195cc-f877-463a-8657-62286162efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 6: Frequency Encoding\n",
    "if 'package' in data.columns:\n",
    "    data['frequency_encoded'] = data['package'].map(data['package'].value_counts(normalize=True))\n",
    "    data.to_csv('encoded_data/frequency_encoded.csv', index=False)\n",
    "else:\n",
    "    print(\"Column 'package' does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f6052d6-748d-4657-8fac-c5d1d25b2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method 7: Hashing Encoding\n",
    "hasher = HashingEncoder(n_components=8)\n",
    "hashed_data = hasher.fit_transform(data)\n",
    "hashed_data.to_csv('encoded_data/hashing_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb3f9de3-5427-4e33-bc04-6037af7b7fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aim2r\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\aim2r\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Method 8: Helmert Encoding\n",
    "he = HelmertEncoder()\n",
    "he_data = he.fit_transform(data)\n",
    "\n",
    "he_data.drop(columns=he_data.filter(like='frequency').columns, inplace=True)\n",
    "\n",
    "he_data.to_csv('encoded_data/helmert_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "235b5c3b-6034-4d5e-a0b9-17550b1d7980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aim2r\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\aim2r\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Method 9: Sum Coding\n",
    "sum_encoder = SumEncoder()\n",
    "sum_data = sum_encoder.fit_transform(data)\n",
    "\n",
    "sum_data.drop(columns=sum_data.filter(like='frequency').columns, inplace=True)\n",
    "\n",
    "sum_data.to_csv('encoded_data/sum_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49b06ab4-bf90-407e-b940-b53a824e2be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aim2r\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\aim2r\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "# Method 10: Backward Difference Encoding\n",
    "bde = BackwardDifferenceEncoder()\n",
    "bde_data = bde.fit_transform(data)\n",
    "\n",
    "bde_data.drop(columns=bde_data.filter(like='frequency').columns, inplace=True)\n",
    "\n",
    "bde_data.to_csv('encoded_data/backwarddifference_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55995497-dcd9-4db1-8242-98c82a98212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aim2r\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\aim2r\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Method 11: Polynomial Encoding\n",
    "pe = PolynomialEncoder()\n",
    "pe_data = pe.fit_transform(data[categorical_columns])\n",
    "\n",
    "# Add the 'target' column from the original data\n",
    "pe_data['target'] = data['target']\n",
    "\n",
    "pe_data.to_csv('encoded_data/polynomial_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb268b0c-31f4-41e0-82dd-1b9c2fa9c918",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method 12: Leave-One-Out Encoding\n",
    "loe = LeaveOneOutEncoder()\n",
    "loe_data = loe.fit_transform(data, data['target'])\n",
    "\n",
    "loe_data.drop(columns=loe_data.filter(like='frequency').columns, inplace=True)\n",
    "\n",
    "\n",
    "loe_data.to_csv('encoded_data/leaveoneout_encoded.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54440c47-0c83-4b0c-a488-871a6232bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Method 13: CatBoost Encoding\n",
    "cbe = CatBoostEncoder()\n",
    "cbe_data = cbe.fit_transform(data, data['target'])\n",
    "\n",
    "cbe_data.drop(columns=cbe_data.filter(like='frequency').columns, inplace=True)\n",
    "\n",
    "cbe_data.to_csv('encoded_data/catboost_encoded.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "490a42e2-b640-4d4c-ba13-6dd3db5e0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Method 14: James-Stein Encoding\n",
    "jse = JamesSteinEncoder()\n",
    "jse_data = jse.fit_transform(data, data['target'])\n",
    "\n",
    "# jse_data.drop(columns=jse_data.filter(like='frequency').columns, inplace=True)\n",
    "\n",
    "\n",
    "jse_data.to_csv('encoded_data/jamesstein_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f746abc-7d7c-40bc-832f-ae72cfcc64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 15: M-Estimate Encoding\n",
    "me = MEstimateEncoder()\n",
    "me_data = me.fit_transform(data, data['target'])\n",
    "\n",
    "me_data.drop(columns=me_data.filter(like='frequency').columns, inplace=True)\n",
    "\n",
    "me_data.to_csv('encoded_data/mestimate_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8c83fb8-b46f-4ff1-ad2a-080fae148f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 16: Multiple Correspondence Analysis\n",
    "import pandas as pd\n",
    "import prince  # For Multiple Correspondence Analysis\n",
    "\n",
    "# Assuming 'data' has been loaded and consists of categorical variables\n",
    "\n",
    "# Initialize and fit MCA\n",
    "# Number of components can be chosen based on the number of categorical features or desired dimensionality\n",
    "mca = prince.MCA(n_components=4, random_state=42)\n",
    "mca_data = mca.fit(data)\n",
    "\n",
    "# Transform the dataset and create a DataFrame of the transformed data\n",
    "mca_transformed = mca.transform(data)\n",
    "mca_transformed.columns = [f'MCA_{i}' for i in range(mca_transformed.shape[1])]\n",
    "\n",
    "mca_transformed['target'] = data['target']\n",
    "\n",
    "\n",
    "mca_transformed.to_csv('encoded_data/mca_encoded.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f17e50-2755-44e8-898e-2429b44b88cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89300683-a481-4701-aaf4-9012f4510ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
